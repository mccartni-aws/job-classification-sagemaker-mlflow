{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Fine-Tuning for Job Description Classification with SageMaker & MLflow\n",
    "\n",
    "This notebook orchestrates a SageMaker Pipeline to fine-tune Llama 3 for job description classification. \n",
    "It uses pre-generated raw data from S3 (created by `scripts/python/generate_and_upload_raw_data.py`), \n",
    "a dedicated training script (`scripts/python/finetune_entrypoint.py`), and MLflow for experiment tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "**Important:** If you encounter `OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/fsspec-XYZ.dist-info/METADATA'`, run the following in a new cell first, then **RESTART THE KERNEL** and run this cell again:\n",
    "```python\n",
    "# !pip install --ignore-installed --no-deps --no-cache-dir fsspec==2023.6.0 # Or the problematic version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05af8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting fsspec==2023.6.0\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "Successfully installed fsspec-2023.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --ignore-installed --no-deps --no-cache-dir fsspec==2023.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442307c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker  datasets transformers mlflow sagemaker-mlflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"sagemaker>=2.200.0\" \"datasets>=2.18.0\" \"transformers>=4.38.0,<4.41.0\" \"mlflow>=2.9.0\" \"sagemaker-mlflow>=0.1.0\" --quiet\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet # Ensure cuXXX matches your training instance GPU CUDA version\n",
    "# !pip install \"accelerate>=0.28.0\" \"bitsandbytes>=0.41.0,<0.43.0\" \"scikit-learn>=1.0.0\" \"pandas\" \"matplotlib\" \"seaborn\" \"huggingface_hub\" \"s3fs\" \"peft>=0.9.0,<0.12.0\" --quiet # Pin peft for transformers 4.36-4.40 compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "Adding project root to sys.path: /home/sagemaker-user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.7.0+cu118 available.\n",
      "INFO:datasets:TensorFlow version 2.12.1 available.\n",
      "INFO:datasets:JAX version 0.4.20 available.\n",
      "2025-05-30 00:54:10.649033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterInteger, ParameterFloat\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "# --- Add project root to sys.path for local module imports ---\n",
    "import sys\n",
    "notebook_dir = os.getcwd() \n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "if project_root not in sys.path:\n",
    "    print(f\"Adding project root to sys.path: {project_root}\")\n",
    "    sys.path.insert(0, project_root)\n",
    "else:\n",
    "    print(f\"Project root already in sys.path: {project_root}\")\n",
    "# --- End Path Setup ---\n",
    "\n",
    "# Import functions from your scripts\n",
    "from steps.preprocess_job_descriptions import preprocess_data\n",
    "from steps.finetune_llama3_classifier import launch_hf_training_job # This is your LAUNCHER script's main function\n",
    "from steps.evaluation_classifier import evaluate_model\n",
    "\n",
    "# os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SageMaker Session and IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413c63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.environ.get(\"AWS_ROLE_ARN\"))\n",
    "\n",
    "# import boto3\n",
    "# try:\n",
    "#     client = boto3.client('sts')\n",
    "#     identity = client.get_caller_identity()\n",
    "#     print(identity)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error getting caller identity: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a3a7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role: arn:aws:iam::174671970284:role/service-role/AmazonSageMaker-ExecutionRole-20240216T153805\n",
      "Region: us-east-1\n",
      "Default bucket: sagemaker-us-east-1-174671970284\n"
     ]
    }
   ],
   "source": [
    "# Create session with explicit boto session to avoid config issues\n",
    "boto_session = boto3.Session(region_name='us-east-1')\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "region = sess.boto_region_name\n",
    "default_bucket = sess.default_bucket()\n",
    "\n",
    "print(f\"SageMaker Execution Role: {role}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Default bucket: {default_bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role: arn:aws:iam::174671970284:role/service-role/AmazonSageMaker-ExecutionRole-20240216T153805\n",
      "SageMaker Session region: us-east-1, bucket: sagemaker-us-east-1-174671970284\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(f\"SageMaker Execution Role: {role}\")\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    print(\"Could not automatically get SageMaker execution role. Please ensure it's configured or specify manually.\")\n",
    "    raise ValueError(\"SageMaker execution role not found.\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "default_bucket = sess.default_bucket()\n",
    "print(f\"SageMaker Session region: {region}, bucket: {default_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Default RawDatasetS3URI is set to 's3://sagemaker-us-east-1-174671970284/raw_job_data/poc_multilingual_01/raw_jds_translated.jsonl'. Ensure this S3 URI points to your generated raw dataset or override this parameter when starting the pipeline.\n"
     ]
    }
   ],
   "source": [
    "pipeline_name = \"JobDescClassification-Llama3-Pipeline-V5\" \n",
    "base_job_prefix = \"job-desc-classify\" \n",
    "\n",
    "mlflow_tracking_server_arn = \"arn:aws:sagemaker:us-east-1:174671970284:mlflow-tracking-server/mlflow-d-8mkvrvo3fobb-27-10-47-37\" # <--- REPLACE THIS\n",
    "mlflow_experiment_name = \"JobDescriptionClassification-Llama3-FineTuning\"\n",
    "\n",
    "model_id_default = \"meta-llama/Meta-Llama-3-8B\" \n",
    "\n",
    "processed_data_s3_prefix = f\"{base_job_prefix}/processed_data/v3\" \n",
    "\n",
    "default_raw_data_s3_uri = f\"s3://{default_bucket}/raw_job_data/poc_multilingual_01/raw_jds_translated.jsonl\" \n",
    "\n",
    "preprocess_instance_type = \"ml.m5.large\"\n",
    "finetune_launcher_instance_type = \"ml.m5.large\" \n",
    "default_training_instance_type = \"ml.g5.12xlarge\" \n",
    "evaluation_instance_type = \"ml.g5.2xlarge\" \n",
    "\n",
    "default_hf_training_image_uri = f'763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-training:2.1.0-transformers4.36.0-gpu-py310-cu121-ubuntu20.04'\n",
    "\n",
    "if \"your-region\" in mlflow_tracking_server_arn:\n",
    "    print(\"ERROR: MLflow Tracking Server ARN is a placeholder. Please replace it.\")\n",
    "if \"raw_job_data/poc_multilingual_01/raw_jds_translated.jsonl\" in default_raw_data_s3_uri:\n",
    "    # This is a very basic check and might not be accurate for all S3 path styles\n",
    "    print(f\"WARNING: Default RawDatasetS3URI is set to '{default_raw_data_s3_uri}'. Ensure this S3 URI points to your generated raw dataset or override this parameter when starting the pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_raw_data_s3_uri = ParameterString(name=\"RawDatasetS3URI\", default_value=default_raw_data_s3_uri)\n",
    "param_job_desc_column = ParameterString(name=\"JobDescriptionColumn\", default_value=\"job_description_text\")\n",
    "param_category_column = ParameterString(name=\"CategoryColumn\", default_value=\"category_label\")\n",
    "param_test_split_fraction = ParameterFloat(name=\"TestSplitFraction\", default_value=0.15)\n",
    "param_validation_split_fraction = ParameterFloat(name=\"ValidationSplitFraction\", default_value=0.15)\n",
    "param_max_samples_per_split = ParameterInteger(name=\"MaxSamplesPerSplit\", default_value=-1)\n",
    "\n",
    "param_model_id = ParameterString(name=\"ModelIdentifier\", default_value=model_id_default)\n",
    "param_training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=default_training_instance_type)\n",
    "param_training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=1)\n",
    "param_hf_training_image_uri = ParameterString(name=\"HFTrainingImageURI\", default_value=default_hf_training_image_uri)\n",
    "\n",
    "param_finetune_epochs = ParameterInteger(name=\"FineTuneEpochs\", default_value=1)\n",
    "param_per_device_train_batch_size = ParameterInteger(name=\"PerDeviceTrainBatchSize\", default_value=1)\n",
    "param_learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.0002)\n",
    "param_lora_r = ParameterInteger(name=\"LoraR\", default_value=8)\n",
    "param_lora_alpha = ParameterInteger(name=\"LoraAlpha\", default_value=16)\n",
    "param_lora_dropout = ParameterFloat(name=\"LoraDropout\", default_value=0.05)\n",
    "param_lora_target_modules = ParameterString(name=\"LoraTargetModules\", default_value=\"q_proj,v_proj,k_proj,o_proj\")\n",
    "param_merge_weights = ParameterString(name=\"MergeWeights\", default_value=\"True\")\n",
    "param_hf_token = ParameterString(name=\"HuggingFaceToken\", default_value=\"OPTIONAL_HF_TOKEN_PLACEHOLDER\")\n",
    "\n",
    "param_eval_batch_size = ParameterInteger(name=\"EvaluationBatchSize\", default_value=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Pipeline Steps using `@step` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Preprocessing Step\n",
    "@step(\n",
    "    name=\"PreprocessJobData\",\n",
    "    instance_type=preprocess_instance_type,\n",
    "    keep_alive_period_in_seconds=300\n",
    ")\n",
    "def sm_pipeline_preprocess_data_step(\n",
    "    raw_s3_uri: str,\n",
    "    s3_bucket: str,\n",
    "    s3_prefix: str,\n",
    "    jd_column: str,\n",
    "    cat_column: str,\n",
    "    test_frac_val: float,\n",
    "    val_frac_val: float,\n",
    "    max_samples_val: int,\n",
    "    mlflow_arn_val: str,\n",
    "    mlflow_exp_val: str,\n",
    "    exec_id: str,\n",
    "):\n",
    "    actual_max_samples = None if max_samples_val < 0 else max_samples_val\n",
    "    return preprocess_data(\n",
    "        raw_dataset_identifier=raw_s3_uri,\n",
    "        s3_output_bucket=s3_bucket,\n",
    "        s3_output_prefix=s3_prefix,\n",
    "        job_desc_column=jd_column,\n",
    "        category_column=cat_column,\n",
    "        test_split_fraction=test_frac_val,\n",
    "        validation_from_train_fraction=val_frac_val,\n",
    "        max_samples_per_split=actual_max_samples,\n",
    "        mlflow_arn=mlflow_arn_val,\n",
    "        experiment_name=mlflow_exp_val,\n",
    "        run_name=exec_id,\n",
    "    )\n",
    "\n",
    "# B. Fine-tuning Launcher Step\n",
    "@step(\n",
    "    name=\"LaunchHFFineTuning\",\n",
    "    instance_type=finetune_launcher_instance_type, \n",
    "    keep_alive_period_in_seconds=300 \n",
    ")\n",
    "def sm_pipeline_finetune_launcher_step(\n",
    "    processed_data_info_dict: dict,\n",
    "    sagemaker_iam_role: str,\n",
    "    train_instance_type_str: str,\n",
    "    train_instance_count_int: int,\n",
    "    hf_image_uri_str: str,\n",
    "    model_id_str: str,\n",
    "    epochs_int: int,\n",
    "    batch_size_int: int,\n",
    "    lr_float: float,\n",
    "    lora_r_int: int,\n",
    "    lora_alpha_int: int,\n",
    "    lora_dropout_float: float,\n",
    "    lora_targets_str: str,\n",
    "    merge_weights_str: str,\n",
    "    hf_token_str: str,\n",
    "    mlflow_arn_str: str,\n",
    "    mlflow_exp_str: str,\n",
    "    pipeline_exec_id_str: str,\n",
    "):\n",
    "    merge_weights_bool = merge_weights_str.lower() == 'true'\n",
    "    actual_hf_token = hf_token_str if hf_token_str and hf_token_str != \"OPTIONAL_HF_TOKEN_PLACEHOLDER\" else None\n",
    "    \n",
    "    # launch_hf_training_job is from steps.finetune_llama3_classifier (your launcher script)\n",
    "    # Ensure this launcher script internally sets source_dir=\"scripts\" and entry_point=\"python/finetune_entrypoint.py\"\n",
    "    return launch_hf_training_job(\n",
    "        role=sagemaker_iam_role,\n",
    "        image_uri=hf_image_uri_str,\n",
    "        instance_type=train_instance_type_str,\n",
    "        instance_count=train_instance_count_int,\n",
    "        train_s3_uri=processed_data_info_dict['train'],\n",
    "        validation_s3_uri=processed_data_info_dict['validation'],\n",
    "        # The following two are now expected to be hardcoded/managed within your launcher script:\n",
    "        entry_point_script=\"python/finetune_entrypoint.py\", # This should match what your launcher expects or uses internally\n",
    "        source_directory=\"scripts\", # This should match what your launcher expects or uses internally\n",
    "        model_id_hf=model_id_str,\n",
    "        epochs_val=epochs_int,\n",
    "        per_device_train_batch_size_val=batch_size_int,\n",
    "        learning_rate_val=lr_float,\n",
    "        lora_r_val=lora_r_int,\n",
    "        lora_alpha_val=lora_alpha_int,\n",
    "        lora_dropout_val=lora_dropout_float,\n",
    "        lora_target_modules_val=lora_targets_str,\n",
    "        merge_weights_val=merge_weights_bool,\n",
    "        hf_token_val=actual_hf_token,\n",
    "        mlflow_tracking_arn=mlflow_arn_str,\n",
    "        mlflow_experiment=mlflow_exp_str,\n",
    "        pipeline_run_id=pipeline_exec_id_str,\n",
    "        base_job_name_prefix=f\"job-clf-{model_id_str.split('/')[-1].replace('_','-')}\"\n",
    "    )\n",
    "\n",
    "# C. Evaluation Step\n",
    "@step(\n",
    "    name=\"EvaluateClassifier\",\n",
    "    instance_type=evaluation_instance_type,\n",
    "    image_uri=default_hf_training_image_uri, \n",
    "    keep_alive_period_in_seconds=600\n",
    ")\n",
    "def sm_pipeline_evaluate_model_step(\n",
    "    finetune_launcher_output_dict: dict, \n",
    "    processed_data_info_dict: dict, \n",
    "    eval_batch_size_int: int, \n",
    "    mlflow_arn_str: str,\n",
    "    mlflow_exp_str: str,\n",
    "    pipeline_exec_id_str: str \n",
    "):\n",
    "    mlflow_model_uri = f\"runs:/{pipeline_exec_id_str}/fine_tuned_classifier_model\" \n",
    "    \n",
    "    return evaluate_model(\n",
    "        model_s3_path_or_mlflow_uri=mlflow_model_uri, \n",
    "        test_data_s3_path=processed_data_info_dict['test'],\n",
    "        poc_categories_s3_path=processed_data_info_dict['categories_s3_path'],\n",
    "        batch_size=eval_batch_size_int,\n",
    "        mlflow_arn=mlflow_arn_str,\n",
    "        experiment_name=mlflow_exp_str,\n",
    "        run_id=pipeline_exec_id_str \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construct the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_step_output_data = sm_pipeline_preprocess_data_step(\n",
    "    raw_s3_uri=param_raw_data_s3_uri,\n",
    "    s3_bucket=default_bucket, \n",
    "    s3_prefix=processed_data_s3_prefix,\n",
    "    jd_column=param_job_desc_column,\n",
    "    cat_column=param_category_column,\n",
    "    test_frac_val=param_test_split_fraction,\n",
    "    val_frac_val=param_validation_split_fraction,\n",
    "    max_samples_val=param_max_samples_per_split, \n",
    "    mlflow_arn_val=mlflow_tracking_server_arn, \n",
    "    mlflow_exp_val=mlflow_experiment_name, \n",
    "    exec_id=ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    ")\n",
    "\n",
    "finetune_step_output_data = sm_pipeline_finetune_launcher_step(\n",
    "    processed_data_info_dict=preprocess_step_output_data, \n",
    "    sagemaker_iam_role=role, \n",
    "    train_instance_type_str=param_training_instance_type,\n",
    "    train_instance_count_int=param_training_instance_count,\n",
    "    hf_image_uri_str=param_hf_training_image_uri,\n",
    "    model_id_str=param_model_id, \n",
    "    epochs_int=param_finetune_epochs,\n",
    "    batch_size_int=param_per_device_train_batch_size,\n",
    "    lr_float=param_learning_rate,\n",
    "    lora_r_int=param_lora_r,\n",
    "    lora_alpha_int=param_lora_alpha,\n",
    "    lora_dropout_float=param_lora_dropout,\n",
    "    lora_targets_str=param_lora_target_modules,\n",
    "    merge_weights_str=param_merge_weights,\n",
    "    hf_token_str=param_hf_token,\n",
    "    mlflow_arn_str=mlflow_tracking_server_arn,\n",
    "    mlflow_exp_str=mlflow_experiment_name,\n",
    "    pipeline_exec_id_str=ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    ")\n",
    "\n",
    "evaluate_step_output_data = sm_pipeline_evaluate_model_step(\n",
    "    finetune_launcher_output_dict=finetune_step_output_data, \n",
    "    processed_data_info_dict=preprocess_step_output_data, \n",
    "    eval_batch_size_int=param_eval_batch_size,\n",
    "    mlflow_arn_str=mlflow_tracking_server_arn,\n",
    "    mlflow_exp_str=mlflow_experiment_name,\n",
    "    pipeline_exec_id_str=ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        param_raw_data_s3_uri,\n",
    "        param_job_desc_column,\n",
    "        param_category_column,\n",
    "        param_test_split_fraction,\n",
    "        param_validation_split_fraction,\n",
    "        param_max_samples_per_split,\n",
    "        param_model_id,\n",
    "        param_training_instance_type,\n",
    "        param_training_instance_count,\n",
    "        param_hf_training_image_uri,\n",
    "        param_finetune_epochs,\n",
    "        param_per_device_train_batch_size,\n",
    "        param_learning_rate,\n",
    "        param_lora_r,\n",
    "        param_lora_alpha,\n",
    "        param_lora_dropout,\n",
    "        param_lora_target_modules,\n",
    "        param_merge_weights,\n",
    "        param_hf_token,\n",
    "        param_eval_batch_size\n",
    "    ],\n",
    "    steps=[evaluate_step_output_data],\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upsert and Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 01:30:51,752 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/EvaluateClassifier/2025-05-30-01-30-51-752/function\n",
      "2025-05-30 01:30:51,878 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/EvaluateClassifier/2025-05-30-01-30-51-752/arguments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Upserting the pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-05-30 01:30:52,100 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/LaunchHFFineTuning/2025-05-30-01-30-51-752/function\n",
      "2025-05-30 01:30:52,172 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/LaunchHFFineTuning/2025-05-30-01-30-51-752/arguments\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-05-30 01:30:52,262 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/PreprocessJobData/2025-05-30-01-30-51-752/function\n",
      "2025-05-30 01:30:52,319 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/PreprocessJobData/2025-05-30-01-30-51-752/arguments\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-05-30 01:30:52,820 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/EvaluateClassifier/2025-05-30-01-30-52-820/function\n",
      "2025-05-30 01:30:52,880 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/EvaluateClassifier/2025-05-30-01-30-52-820/arguments\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-05-30 01:30:53,065 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/LaunchHFFineTuning/2025-05-30-01-30-52-820/function\n",
      "2025-05-30 01:30:53,136 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/LaunchHFFineTuning/2025-05-30-01-30-52-820/arguments\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "2025-05-30 01:30:53,195 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/PreprocessJobData/2025-05-30-01-30-52-820/function\n",
      "2025-05-30 01:30:53,259 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-174671970284/JobDescClassification-Llama3-Pipeline-V5/PreprocessJobData/2025-05-30-01-30-52-820/arguments\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 'JobDescClassification-Llama3-Pipeline-V5' upserted successfully.\n",
      "\n",
      "Starting pipeline execution...\n",
      "Pipeline execution started with ARN: arn:aws:sagemaker:us-east-1:174671970284:pipeline/JobDescClassification-Llama3-Pipeline-V5/execution/k3t6o3jmtm0o\n"
     ]
    }
   ],
   "source": [
    "if \"your-region\" in mlflow_tracking_server_arn:\n",
    "    print(\"ERROR: MLflow Tracking Server ARN is a placeholder. Update it in cell [3].\")\n",
    "else:\n",
    "    print(\"\\nUpserting the pipeline...\")\n",
    "    try:\n",
    "        pipeline.upsert(role_arn=role)\n",
    "        print(f\"Pipeline '{pipeline_name}' upserted successfully.\")\n",
    "\n",
    "        print(\"\\nStarting pipeline execution...\")\n",
    "        execution = pipeline.start(\n",
    "            parameters={}\n",
    "        )\n",
    "        print(f\"Pipeline execution started with ARN: {execution.arn}\")\n",
    "        execution.describe()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during pipeline upsert or start: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clean up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete the pipeline definition from SageMaker:\n",
    "# try:\n",
    "#     pipeline.delete()\n",
    "#     print(f\"Pipeline '{pipeline_name}' deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting pipeline '{pipeline_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "sagemaker": {
   "image_uri": "arn:aws:sagemaker:us-east-1:000000000000:image/sagemaker-data-science-310-v1",
   "instance_type": "ml.t3.medium"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
