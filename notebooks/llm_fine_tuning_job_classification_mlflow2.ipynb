{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Fine-Tuning for Job Description Classification with SageMaker & MLflow\n",
    "\n",
    "This notebook demonstrates fine-tuning Llama 3 for job description classification using SageMaker Pipelines and MLflow for experiment tracking. It assumes raw data has been pre-generated and uploaded to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.200.0\" \"datasets>=2.18.0\" \"transformers>=4.38.0\" \"mlflow>=2.9.0\" \"sagemaker-mlflow>=0.1.0\" --quiet\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet # Adjust cuXXX for your GPU if needed\n",
    "!pip install \"accelerate>=0.28.0\" \"bitsandbytes>=0.42.0\" \"scikit-learn>=1.0.0\" \"pandas\" \"matplotlib\" \"seaborn\" \"huggingface_hub\" \"s3fs\" \"peft>=0.9.0\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker.workflow.parameters import ParameterString, ParameterInteger, ParameterFloat\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "# These imports refer to the scripts in your 'steps/' directory.\n",
    "from steps.preprocess_job_descriptions import preprocess_data\n",
    "from steps.finetune_llama3_classifier import finetune_model # Assuming this is the main function in your finetune script\n",
    "from steps.evaluation_classifier import evaluate_model\n",
    "\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SageMaker Session and IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(f\"SageMaker Execution Role: {role}\")\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    print(\"Could not automatically get SageMaker execution role. Please ensure it's configured or specify manually.\")\n",
    "    # Fallback: Replace with your specific role name if necessary\n",
    "    # role_name = \"YourSageMakerExecutionRoleName\" \n",
    "    # role = iam.get_role(RoleName=role_name)[\"Role\"][\"Arn\"]\n",
    "    raise ValueError(\"SageMaker execution role not found. Please create one or ensure your environment is configured.\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "default_bucket = sess.default_bucket()\n",
    "print(f\"SageMaker Session region: {region}, bucket: {default_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"JobDescClassification-Llama3-Pipeline-V4\" \n",
    "base_job_prefix = \"job-desc-classify\" \n",
    "\n",
    "mlflow_tracking_server_arn = \"arn:aws:sagemaker:your-region:your-aws-account-id:mlflow-tracking-server/your-tracking-server-name\" # <--- REPLACE THIS\n",
    "mlflow_experiment_name = \"JobDescriptionClassification-Llama3-FineTuning\"\n",
    "\n",
    "model_id_default = \"meta-llama/Meta-Llama-3-8B\" \n",
    "\n",
    "processed_data_s3_prefix = f\"{base_job_prefix}/processed_data/v2\" # Example prefix for processed data\n",
    "\n",
    "preprocess_instance_type = \"ml.m5.large\"\n",
    "finetune_instance_type = \"ml.g5.12xlarge\" \n",
    "evaluation_instance_type = \"ml.g5.2xlarge\" \n",
    "\n",
    "if \"your-region\" in mlflow_tracking_server_arn:\n",
    "    print(\"WARNING: MLflow Tracking Server ARN is a placeholder. Please replace it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_raw_data_s3_uri = ParameterString(\n",
    "    name=\"RawDatasetS3URI\", \n",
    "    default_value=f\"s3://{default_bucket}/raw_job_description_data/v1_translated/raw_jds_translated.jsonl\" # Example default\n",
    ")\n",
    "param_job_desc_column = ParameterString(name=\"JobDescriptionColumn\", default_value=\"job_description_text\")\n",
    "param_category_column = ParameterString(name=\"CategoryColumn\", default_value=\"category_label\")\n",
    "param_test_split_fraction = ParameterFloat(name=\"TestSplitFraction\", default_value=0.15)\n",
    "param_validation_split_fraction = ParameterFloat(name=\"ValidationSplitFraction\", default_value=0.15)\n",
    "param_max_samples_per_split = ParameterInteger(name=\"MaxSamplesPerSplit\", default_value=-1) # -1 means no limit, use 0 or None in script\n",
    "\n",
    "param_model_id = ParameterString(name=\"ModelIdentifier\", default_value=model_id_default)\n",
    "param_finetune_epochs = ParameterInteger(name=\"FineTuneEpochs\", default_value=1)\n",
    "param_per_device_train_batch_size = ParameterInteger(name=\"PerDeviceTrainBatchSize\", default_value=1)\n",
    "param_lora_r = ParameterInteger(name=\"LoraR\", default_value=8)\n",
    "param_lora_alpha = ParameterInteger(name=\"LoraAlpha\", default_value=16)\n",
    "param_lora_dropout = ParameterFloat(name=\"LoraDropout\", default_value=0.05)\n",
    "param_learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.0002)\n",
    "param_merge_weights = ParameterString(name=\"MergeWeights\", default_value=\"True\") # Use String for boolean-like params\n",
    "param_hf_token = ParameterString(name=\"HuggingFaceToken\", default_value=\"OPTIONAL_HF_TOKEN_PLACEHOLDER\")\n",
    "\n",
    "param_eval_batch_size = ParameterInteger(name=\"EvaluationBatchSize\", default_value=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Pipeline Steps using `@step` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Preprocessing Step\n",
    "@step(\n",
    "    name=\"PreprocessRawJobData\",\n",
    "    instance_type=preprocess_instance_type,\n",
    "    keep_alive_period_in_seconds=300\n",
    ")\n",
    "def sm_pipeline_preprocess_step(\n",
    "    raw_data_s3_identifier: str,\n",
    "    output_s3_bucket_name: str,\n",
    "    output_s3_prefix_val: str,\n",
    "    jd_col: str,\n",
    "    cat_col: str,\n",
    "    test_frac: float,\n",
    "    val_frac: float,\n",
    "    max_samples: int, # Corresponds to max_samples_per_split\n",
    "    mlflow_arn_tracking: str,\n",
    "    mlflow_exp_name: str,\n",
    "    pipeline_exec_id: str,\n",
    "):\n",
    "    # The imported 'preprocess_data' is from 'steps/preprocess_job_descriptions.py'\n",
    "    max_samples_val = None if max_samples < 0 else max_samples # Convert -1 to None for the script\n",
    "    s3_paths_and_run_id = preprocess_data(\n",
    "        raw_dataset_identifier=raw_data_s3_identifier,\n",
    "        s3_output_bucket=output_s3_bucket_name,\n",
    "        s3_output_prefix=output_s3_prefix_val,\n",
    "        job_desc_column=jd_col,\n",
    "        category_column=cat_col,\n",
    "        test_split_fraction=test_frac,\n",
    "        validation_from_train_fraction=val_frac,\n",
    "        max_samples_per_split=max_samples_val,\n",
    "        mlflow_arn=mlflow_arn_tracking,\n",
    "        experiment_name=mlflow_exp_name,\n",
    "        run_name=pipeline_exec_id,\n",
    "    )\n",
    "    return s3_paths_and_run_id\n",
    "\n",
    "# B. Fine-tuning Step\n",
    "hf_pytorch_image_uri = sagemaker.image_uris.retrieve(\n",
    "    \"huggingface-pytorch-training\",\n",
    "    region=region,\n",
    "    version=\"4.31.0\", \n",
    "    py_version=\"py310\",\n",
    "    instance_type=finetune_instance_type, \n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(f\"Using HuggingFace PyTorch image for fine-tuning: {hf_pytorch_image_uri}\")\n",
    "\n",
    "@step(\n",
    "    name=\"FineTuneLlama3Classifier\",\n",
    "    instance_type=finetune_instance_type,\n",
    "    image_uri=hf_pytorch_image_uri, \n",
    "    keep_alive_period_in_seconds=3600 \n",
    ")\n",
    "def sm_pipeline_finetune_step(\n",
    "    processed_data_info: dict, \n",
    "    model_identifier_str: str,\n",
    "    epochs_ft: int,\n",
    "    batch_size_ft: int,\n",
    "    lora_r_val: int,\n",
    "    lora_alpha_val: int,\n",
    "    lora_dropout_val: float,\n",
    "    lr_val: float,\n",
    "    merge_w: str, # String 'True' or 'False'\n",
    "    mlflow_arn_tracking: str,\n",
    "    mlflow_exp_name: str,\n",
    "    pipeline_exec_id: str,\n",
    "    hf_auth_token: str\n",
    "):\n",
    "    # The imported 'finetune_model' is from 'steps/finetune_llama3_classifier.py'\n",
    "    actual_hf_token = hf_auth_token if hf_auth_token and hf_auth_token != \"OPTIONAL_HF_TOKEN_PLACEHOLDER\" else os.environ.get(\"HF_TOKEN\")\n",
    "    merge_weights_bool = merge_w.lower() == 'true'\n",
    "    \n",
    "    # finetune_model script saves to /opt/ml/model by default.\n",
    "    # The S3 path of this uploaded model artifact will be the output of this step.\n",
    "    local_model_output_path = finetune_model(\n",
    "        model_id=model_identifier_str,\n",
    "        train_data_s3_path=processed_data_info['train'],\n",
    "        eval_data_s3_path=processed_data_info['validation'],\n",
    "        # output_dir is handled by the script, defaults to /opt/ml/model\n",
    "        epochs=epochs_ft,\n",
    "        per_device_train_batch_size=batch_size_ft,\n",
    "        learning_rate=lr_val,\n",
    "        lora_r=lora_r_val,\n",
    "        lora_alpha=lora_alpha_val,\n",
    "        lora_dropout=lora_dropout_val,\n",
    "        merge_weights=merge_weights_bool,\n",
    "        hf_token=actual_hf_token,\n",
    "        mlflow_arn=mlflow_arn_tracking,\n",
    "        experiment_name=mlflow_exp_name,\n",
    "        run_id=pipeline_exec_id \n",
    "    )\n",
    "    # The @step decorator uploads /opt/ml/model. We return a dict for clarity for the next step.\n",
    "    return {\"model_s3_path_implicit\": \"s3_path_managed_by_sagemaker_for_opt_ml_model\", \"mlflow_run_id\": pipeline_exec_id} \n",
    "\n",
    "# C. Evaluation Step\n",
    "@step(\n",
    "    name=\"EvaluateFineTunedClassifier\",\n",
    "    instance_type=evaluation_instance_type,\n",
    "    image_uri=hf_pytorch_image_uri,\n",
    "    keep_alive_period_in_seconds=600\n",
    ")\n",
    "def sm_pipeline_evaluate_step(\n",
    "    finetune_step_output: dict, # Contains mlflow_run_id for constructing MLflow model URI\n",
    "    processed_data_info: dict, # Contains 'test' and 'categories_s3_path'\n",
    "    eval_bs: int, \n",
    "    mlflow_arn_tracking: str,\n",
    "    mlflow_exp_name: str,\n",
    "    pipeline_exec_id: str # This is the overall pipeline execution ID\n",
    "):\n",
    "    # The imported 'evaluate_model' is from 'steps/evaluation_classifier.py'\n",
    "    # Construct MLflow model URI from the pipeline_exec_id (which was used as run_id for finetuning)\n",
    "    # Assuming finetune_model logged model as 'fine_tuned_classifier_model' artifact\n",
    "    mlflow_model_uri_to_load = f\"runs:/{pipeline_exec_id}/fine_tuned_classifier_model\" \n",
    "    \n",
    "    eval_results = evaluate_model(\n",
    "        model_s3_path_or_mlflow_uri=mlflow_model_uri_to_load, \n",
    "        test_data_s3_path=processed_data_info['test'],\n",
    "        poc_categories_s3_path=processed_data_info['categories_s3_path'],\n",
    "        batch_size=eval_bs,\n",
    "        mlflow_arn=mlflow_arn_tracking,\n",
    "        experiment_name=mlflow_exp_name,\n",
    "        run_id=pipeline_exec_id # Evaluate logs under the same parent run_id\n",
    "    )\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construct the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_outputs = sm_pipeline_preprocess_step(\n",
    "    raw_data_s3_identifier=param_raw_data_s3_uri,\n",
    "    output_s3_bucket_name=default_bucket, \n",
    "    output_s3_prefix_val=processed_data_s3_prefix,\n",
    "    jd_col=param_job_desc_column,\n",
    "    cat_col=param_category_column,\n",
    "    test_frac=param_test_split_fraction,\n",
    "    val_frac=param_validation_split_fraction,\n",
    "    max_samples=param_max_samples_per_split, \n",
    "    mlflow_arn_tracking=mlflow_tracking_server_arn, \n",
    "    mlflow_exp_name=mlflow_experiment_name, \n",
    "    pipeline_exec_id=ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    ")\n",
    "\n",
    "finetune_outputs = sm_pipeline_finetune_step(\n",
    "    processed_data_info=preprocess_outputs, \n",
    "    model_identifier_str=param_model_id, \n",
    "    epochs_ft=param_finetune_epochs,\n",
    "    batch_size_ft=param_per_device_train_batch_size,\n",
    "    lora_r_val=param_lora_r,\n",
    "    lora_alpha_val=param_lora_alpha,\n",
    "    lora_dropout_val=param_lora_dropout,\n",
    "    lr_val=param_learning_rate,\n",
    "    merge_w=param_merge_weights,\n",
    "    mlflow_arn_tracking=mlflow_tracking_server_arn,\n",
    "    mlflow_exp_name=mlflow_experiment_name,\n",
    "    pipeline_exec_id=ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "    hf_auth_token=param_hf_token\n",
    ")\n",
    "\n",
    "evaluate_outputs = sm_pipeline_evaluate_step(\n",
    "    finetune_step_output=finetune_outputs, \n",
    "    processed_data_info=preprocess_outputs, \n",
    "    eval_bs=param_eval_batch_size,\n",
    "    mlflow_arn_tracking=mlflow_tracking_server_arn,\n",
    "    mlflow_exp_name=mlflow_experiment_name,\n",
    "    pipeline_exec_id=ExecutionVariables.PIPELINE_EXECUTION_ID\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        param_raw_data_s3_uri,\n",
    "        param_job_desc_column,\n",
    "        param_category_column,\n",
    "        param_test_split_fraction,\n",
    "        param_validation_split_fraction,\n",
    "        param_max_samples_per_split,\n",
    "        param_model_id,\n",
    "        param_finetune_epochs,\n",
    "        param_per_device_train_batch_size,\n",
    "        param_lora_r,\n",
    "        param_lora_alpha,\n",
    "        param_lora_dropout,\n",
    "        param_learning_rate,\n",
    "        param_merge_weights,\n",
    "        param_hf_token,\n",
    "        param_eval_batch_size\n",
    "    ],\n",
    "    steps=[evaluate_outputs],\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upsert and Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"your-region\" in mlflow_tracking_server_arn:\n",
    "    print(\"ERROR: MLflow Tracking Server ARN is a placeholder. Update it in cell [3].\")\n",
    "elif \"raw_job_description_data/v1_translated/raw_jds_translated.jsonl\" in param_raw_data_s3_uri.default_value:\n",
    "    print(f\"INFO: Using default RawDatasetS3URI: '{param_raw_data_s3_uri.default_value}'.\")\n",
    "    print(\"       Ensure this S3 URI points to your generated raw dataset or override it when starting the pipeline.\")\n",
    "    print(\"       Run 'generate_and_upload_raw_data.py' script if you haven't already.\")\n",
    "\n",
    "print(\"\\nUpserting the pipeline...\")\n",
    "try:\n",
    "    pipeline.upsert(role_arn=role)\n",
    "    print(f\"Pipeline '{pipeline_name}' upserted successfully.\")\n",
    "\n",
    "    print(\"\\nStarting pipeline execution with default parameters...\")\n",
    "    # To override parameters:\n",
    "    # execution = pipeline.start(\n",
    "    #     parameters={\n",
    "    #         \"RawDatasetS3URI\": \"s3://your-bucket/your-actual-raw-data.jsonl\",\n",
    "    #         \"FineTuneEpochs\": 2\n",
    "    #     }\n",
    "    # )\n",
    "    execution = pipeline.start()\n",
    "    \n",
    "    print(f\"Pipeline execution started with ARN: {execution.arn}\")\n",
    "    execution.describe()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during pipeline upsert or start: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clean up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete the pipeline definition from SageMaker:\n",
    "# try:\n",
    "#     pipeline.delete()\n",
    "#     print(f\"Pipeline '{pipeline_name}' deleted.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting pipeline '{pipeline_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn_aws_sagemaker_us-east-1_000000000000_kernel_data-science-3-10-py310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "sagemaker": {
   "image_uri": "arn:aws:sagemaker:us-east-1:000000000000:image/sagemaker-data-science-310-v1",
   "instance_type": "ml.t3.medium"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}